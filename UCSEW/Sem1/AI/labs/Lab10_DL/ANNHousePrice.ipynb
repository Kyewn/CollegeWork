{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0     8450            7            5          856         2         1   \n",
       "1     9600            6            8         1262         2         0   \n",
       "2    11250            7            5          920         2         1   \n",
       "3     9550            7            5          756         1         0   \n",
       "4    14260            8            5         1145         2         1   \n",
       "\n",
       "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0             3             8           0         548                 1  \n",
       "1             3             6           1         460                 1  \n",
       "2             3             6           1         608                 1  \n",
       "3             3             7           1         642                 0  \n",
       "4             4             9           1         836                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in case tensorflow not functioning, need update VS Studio x64 through\n",
    "#https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "dataset = pd.read_csv('housepricedata.csv')\n",
    "print(dataset.shape)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0        8450            7            5          856         2         1   \n",
       "1        9600            6            8         1262         2         0   \n",
       "2       11250            7            5          920         2         1   \n",
       "3        9550            7            5          756         1         0   \n",
       "4       14260            8            5         1145         2         1   \n",
       "...       ...          ...          ...          ...       ...       ...   \n",
       "1455     7917            6            5          953         2         1   \n",
       "1456    13175            6            6         1542         2         0   \n",
       "1457     9042            7            9         1152         2         0   \n",
       "1458     9717            5            6         1078         1         0   \n",
       "1459     9937            5            6         1256         1         1   \n",
       "\n",
       "      BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0                3             8           0         548                 1  \n",
       "1                3             6           1         460                 1  \n",
       "2                3             6           1         608                 1  \n",
       "3                3             7           1         642                 0  \n",
       "4                4             9           1         836                 1  \n",
       "...            ...           ...         ...         ...               ...  \n",
       "1455             3             7           1         460                 1  \n",
       "1456             3             7           2         500                 1  \n",
       "1457             4             9           2         252                 1  \n",
       "1458             2             5           0         240                 0  \n",
       "1459             3             6           0         276                 0  \n",
       "\n",
       "[1460 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All data is related\n",
    "# No Preprocessing of data needed, since all in numeric\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input features \n",
    "x = dataset.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract output, whether the house is above or below median price\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data, 70% train, 30% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data and normalisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#use fit_transform for training data, as std calculation is needed\n",
    "x_train = sc.fit_transform(x_train)\n",
    "# use transform for test data\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.9913 - accuracy: 0.3376\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8090 - accuracy: 0.3679\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.4834\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.6208 - accuracy: 0.6683\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7378\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7818\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.4524 - accuracy: 0.8053\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8239\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.3851 - accuracy: 0.8395\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8454\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.3432 - accuracy: 0.8591\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8640\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.3142 - accuracy: 0.8708\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8777\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8796\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8816\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8806\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2704 - accuracy: 0.8806\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.8855\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8904\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2518 - accuracy: 0.8904\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8953\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8943\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8924\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.8933\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.8953\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2304 - accuracy: 0.8992\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9002\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9022\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9031\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9061\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9070\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9051\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9061\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2174 - accuracy: 0.9090\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9119\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9100\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9110\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2139 - accuracy: 0.9129\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9159\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9139\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2118 - accuracy: 0.9149\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9139\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2106 - accuracy: 0.9139\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9139\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2096 - accuracy: 0.9139\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9139\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9139\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2076 - accuracy: 0.9149\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9139\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9159\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9149\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9149\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9159\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2045 - accuracy: 0.9159\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2042 - accuracy: 0.9178\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2036 - accuracy: 0.9178\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9178\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9188\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.2027 - accuracy: 0.9188\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9178\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9178\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9178\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.2008 - accuracy: 0.9168\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2007 - accuracy: 0.9168\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9178\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.1998 - accuracy: 0.9168\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9178\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9168\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9178\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9178\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9178\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9178\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9159\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9168\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9178\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9178\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9168\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1963 - accuracy: 0.9178\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9198\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1960 - accuracy: 0.9178\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1956 - accuracy: 0.9188\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9188\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1950 - accuracy: 0.9178\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9198\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1944 - accuracy: 0.9188\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1944 - accuracy: 0.9178\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9178\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1932 - accuracy: 0.9188\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9198\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1928 - accuracy: 0.9207\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9188\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1925 - accuracy: 0.9198\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9198\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1922 - accuracy: 0.9198\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9217\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1916 - accuracy: 0.9198\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1910 - accuracy: 0.9178\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1907 - accuracy: 0.9188\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1904 - accuracy: 0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2850d79d610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us build our ANN network\n",
    "#add layer by layer, hence Sequential\n",
    "ann = tf.keras.models.Sequential()\n",
    "#use Dense function to add layer, 'relu'--> rectifier activation function\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "# use sigmoid as only binary output\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "#stochastic gradient, backpropagation ->adam, binary as only predict yes or no \n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#\n",
    "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(x_test) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(False,)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(False,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(False,)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(False,)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(True,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "(False,)  0\n",
       "(True,)   1\n",
       "(True,)   1\n",
       "(True,)   1\n",
       "(False,)  1\n",
       "...      ..\n",
       "(False,)  0\n",
       "(False,)  0\n",
       "(True,)   1\n",
       "(True,)   1\n",
       "(True,)   1\n",
       "\n",
       "[438 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  21]\n",
      " [ 24 204]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8972602739726028"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cm,annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use our ANN model to predict if the house is above or below: \n",
    "#LotArea: 1000\n",
    "#OveralQual: 6\n",
    "#Cond: 6\n",
    "#TotalBsm: 1000\n",
    "#FullBath: 3\n",
    "#HalfBath: 2\n",
    "#BedroomAbvGr: 4\n",
    "#TotRm: 7\n",
    "#Fireplaces: 0\n",
    "#GarageArea: 500\n",
    "#So, should the house above or below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "#the prediction for a single customer with conditions above, Germany = [0,1,0]\n",
    "#use sc.transform as we have already use standard scaler to transform our data previously\n",
    "print(ann.predict(sc.transform([[1000, 6, 6, 1000, 3, 2, 4, 7, 0, 500]])) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
